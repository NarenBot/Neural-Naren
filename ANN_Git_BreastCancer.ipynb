{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'F:\\Manipal -DS Course\\Raw Data\\Datasets\\breast_cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample = pd.get_dummies(df['diagnosis'], drop_first=True)\n",
    "#y = y.values\n",
    "data_sample = df.drop(['id','diagnosis'], axis=1)\n",
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counts on Target Variable:\n",
    "import matplotlib.pyplot as plt\n",
    "count = df['diagnosis'].value_counts()\n",
    "#count = pd.value_counts(y.values.flatten())\n",
    "count.plot(kind='bar', rot=0)\n",
    "plt.xticks(range(2), ['B','M'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over_Sampling Technique:\n",
    "from imblearn.combine import SMOTETomek\n",
    "smote = SMOTETomek(sampling_strategy=1.0, random_state=42)\n",
    "x_res, y_res = smote.fit_sample(data_sample, y_sample)\n",
    "\n",
    "# Input and Output Variables:\n",
    "y = y_res\n",
    "data = x_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871997</td>\n",
       "      <td>-2.234031</td>\n",
       "      <td>1.035173</td>\n",
       "      <td>0.765518</td>\n",
       "      <td>1.578551</td>\n",
       "      <td>3.218567</td>\n",
       "      <td>2.496040</td>\n",
       "      <td>2.292241</td>\n",
       "      <td>2.237231</td>\n",
       "      <td>2.385837</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617981</td>\n",
       "      <td>-1.518607</td>\n",
       "      <td>2.023739</td>\n",
       "      <td>1.732426</td>\n",
       "      <td>1.251725</td>\n",
       "      <td>2.549821</td>\n",
       "      <td>1.979317</td>\n",
       "      <td>2.086006</td>\n",
       "      <td>2.631415</td>\n",
       "      <td>1.932716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571268</td>\n",
       "      <td>-0.459264</td>\n",
       "      <td>1.432143</td>\n",
       "      <td>1.642041</td>\n",
       "      <td>-0.942895</td>\n",
       "      <td>-0.620777</td>\n",
       "      <td>-0.174951</td>\n",
       "      <td>0.359580</td>\n",
       "      <td>-0.060789</td>\n",
       "      <td>-0.883383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540874</td>\n",
       "      <td>-0.490214</td>\n",
       "      <td>1.287746</td>\n",
       "      <td>1.627174</td>\n",
       "      <td>-0.478638</td>\n",
       "      <td>-0.567374</td>\n",
       "      <td>-0.299646</td>\n",
       "      <td>0.891797</td>\n",
       "      <td>-0.339288</td>\n",
       "      <td>0.231952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     0.871997     -2.234031        1.035173   0.765518         1.578551   \n",
       "1     1.571268     -0.459264        1.432143   1.642041        -0.942895   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          3.218567        2.496040             2.292241       2.237231   \n",
       "1         -0.620777       -0.174951             0.359580      -0.060789   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                2.385837  ...      1.617981      -1.518607         2.023739   \n",
       "1               -0.883383  ...      1.540874      -0.490214         1.287746   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    1.732426          1.251725           2.549821         1.979317   \n",
       "1    1.627174         -0.478638          -0.567374        -0.299646   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0              2.086006        2.631415                 1.932716  \n",
       "1              0.891797       -0.339288                 0.231952  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "data_norm = sc.fit_transform(data)\n",
    "data_norm = pd.DataFrame(data_norm, columns=data_sample.columns)\n",
    "data_norm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test:\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data_norm, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 626us/step - loss: 0.7069 - accuracy: 0.6000 - val_loss: 0.4360 - val_accuracy: 0.8393\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 128us/step - loss: 0.4565 - accuracy: 0.7720 - val_loss: 0.3156 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 136us/step - loss: 0.3011 - accuracy: 0.8600 - val_loss: 0.2454 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.2479 - accuracy: 0.8840 - val_loss: 0.2093 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 130us/step - loss: 0.2401 - accuracy: 0.8980 - val_loss: 0.1813 - val_accuracy: 0.9107\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.2109 - accuracy: 0.9280 - val_loss: 0.1520 - val_accuracy: 0.9286\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.2056 - accuracy: 0.9100 - val_loss: 0.1389 - val_accuracy: 0.9286\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.1945 - accuracy: 0.9280 - val_loss: 0.1358 - val_accuracy: 0.9286\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.1450 - accuracy: 0.9400 - val_loss: 0.1313 - val_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.1295 - accuracy: 0.9600 - val_loss: 0.1252 - val_accuracy: 0.9286\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 132us/step - loss: 0.1428 - accuracy: 0.9440 - val_loss: 0.1315 - val_accuracy: 0.9286\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.1077 - accuracy: 0.9680 - val_loss: 0.1220 - val_accuracy: 0.9464\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 130us/step - loss: 0.1131 - accuracy: 0.9580 - val_loss: 0.1139 - val_accuracy: 0.9464\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 150us/step - loss: 0.0894 - accuracy: 0.9740 - val_loss: 0.1163 - val_accuracy: 0.9464\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 154us/step - loss: 0.0991 - accuracy: 0.9700 - val_loss: 0.1197 - val_accuracy: 0.9464\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 152us/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.1222 - val_accuracy: 0.9464\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 134us/step - loss: 0.0934 - accuracy: 0.9740 - val_loss: 0.1258 - val_accuracy: 0.9464\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 150us/step - loss: 0.0846 - accuracy: 0.9780 - val_loss: 0.1372 - val_accuracy: 0.9464\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 156us/step - loss: 0.0755 - accuracy: 0.9780 - val_loss: 0.1281 - val_accuracy: 0.9464\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 160us/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.1143 - val_accuracy: 0.9464\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 172us/step - loss: 0.1002 - accuracy: 0.9680 - val_loss: 0.1203 - val_accuracy: 0.9464\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 130us/step - loss: 0.0673 - accuracy: 0.9760 - val_loss: 0.1141 - val_accuracy: 0.9464\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.1042 - accuracy: 0.9660 - val_loss: 0.1166 - val_accuracy: 0.9464\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0596 - accuracy: 0.9820 - val_loss: 0.1254 - val_accuracy: 0.9464\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0550 - accuracy: 0.9900 - val_loss: 0.1073 - val_accuracy: 0.9643\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.1150 - val_accuracy: 0.9643\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0371 - accuracy: 0.9920 - val_loss: 0.1185 - val_accuracy: 0.9643\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0605 - accuracy: 0.9780 - val_loss: 0.1316 - val_accuracy: 0.9464\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.1288 - val_accuracy: 0.9464\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0468 - accuracy: 0.9800 - val_loss: 0.1153 - val_accuracy: 0.9643\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0404 - accuracy: 0.9840 - val_loss: 0.1361 - val_accuracy: 0.9464\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0439 - accuracy: 0.9840 - val_loss: 0.1364 - val_accuracy: 0.9464\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0510 - accuracy: 0.9780 - val_loss: 0.1207 - val_accuracy: 0.9643\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.1231 - val_accuracy: 0.9643\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 140us/step - loss: 0.0580 - accuracy: 0.9860 - val_loss: 0.1253 - val_accuracy: 0.9643\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 164us/step - loss: 0.0609 - accuracy: 0.9780 - val_loss: 0.1247 - val_accuracy: 0.9643\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 156us/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.1132 - val_accuracy: 0.9643\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1180 - val_accuracy: 0.9643\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0411 - accuracy: 0.9840 - val_loss: 0.0978 - val_accuracy: 0.9643\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0423 - accuracy: 0.9820 - val_loss: 0.1138 - val_accuracy: 0.9643\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.1090 - val_accuracy: 0.9643\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.1164 - val_accuracy: 0.9643\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 120us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.1194 - val_accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.1356 - val_accuracy: 0.9464\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0225 - accuracy: 0.9960 - val_loss: 0.1312 - val_accuracy: 0.9643\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 0.1251 - val_accuracy: 0.9643\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0239 - accuracy: 0.9860 - val_loss: 0.1290 - val_accuracy: 0.9643\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.1142 - val_accuracy: 0.9643\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.1311 - val_accuracy: 0.9643\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0307 - accuracy: 0.9880 - val_loss: 0.1296 - val_accuracy: 0.9643\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.1237 - val_accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 122us/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.1302 - val_accuracy: 0.9643\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0271 - accuracy: 0.9940 - val_loss: 0.1255 - val_accuracy: 0.9643\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 122us/step - loss: 0.0325 - accuracy: 0.9920 - val_loss: 0.1245 - val_accuracy: 0.9643\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.1257 - val_accuracy: 0.9821\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.0239 - accuracy: 0.9900 - val_loss: 0.1461 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.1519 - val_accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.1466 - val_accuracy: 0.9643\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.1282 - val_accuracy: 0.9821\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0181 - accuracy: 0.9960 - val_loss: 0.1301 - val_accuracy: 0.9821\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0252 - accuracy: 0.9860 - val_loss: 0.1092 - val_accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.0434 - accuracy: 0.9900 - val_loss: 0.1206 - val_accuracy: 0.9821\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0263 - accuracy: 0.9960 - val_loss: 0.1434 - val_accuracy: 0.9643\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0314 - accuracy: 0.9880 - val_loss: 0.1465 - val_accuracy: 0.9643\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.1202 - val_accuracy: 0.9821\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.1212 - val_accuracy: 0.9821\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0169 - accuracy: 0.9980 - val_loss: 0.1292 - val_accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0263 - accuracy: 0.9960 - val_loss: 0.1114 - val_accuracy: 0.9821\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0279 - accuracy: 0.9860 - val_loss: 0.1118 - val_accuracy: 0.9821\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.1205 - val_accuracy: 0.9821\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0204 - accuracy: 0.9900 - val_loss: 0.1305 - val_accuracy: 0.9821\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0173 - accuracy: 0.9920 - val_loss: 0.1319 - val_accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0163 - accuracy: 0.9980 - val_loss: 0.1445 - val_accuracy: 0.9643\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.1416 - val_accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.1458 - val_accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.1355 - val_accuracy: 0.9821\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.1300 - val_accuracy: 0.9821\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.1349 - val_accuracy: 0.9821\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.1360 - val_accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0126 - accuracy: 0.9940 - val_loss: 0.1310 - val_accuracy: 0.9821\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9821\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.1335 - val_accuracy: 0.9821\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.1298 - val_accuracy: 0.9821\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 0.1325 - val_accuracy: 0.9821\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0100 - accuracy: 0.9940 - val_loss: 0.1248 - val_accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1364 - val_accuracy: 0.9821\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.1362 - val_accuracy: 0.9821\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.1474 - val_accuracy: 0.9821\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.1455 - val_accuracy: 0.9821\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.1456 - val_accuracy: 0.9821\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.1411 - val_accuracy: 0.9821\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.1526 - val_accuracy: 0.9821\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0116 - accuracy: 0.9940 - val_loss: 0.1654 - val_accuracy: 0.9821\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9821\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.1533 - val_accuracy: 0.9821\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.1423 - val_accuracy: 0.9821\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 112us/step - loss: 0.0251 - accuracy: 0.9940 - val_loss: 0.1500 - val_accuracy: 0.9821\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0107 - accuracy: 0.9960 - val_loss: 0.1423 - val_accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 110us/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.1420 - val_accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.1444 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12473128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANN Architecture:\n",
    "ann_class = Sequential()\n",
    "ann_class.add(Dense(units=64, kernel_initializer='he_uniform', activation='relu', input_dim=30)) #Input Layer\n",
    "ann_class.add(Dropout(0.3))\n",
    "ann_class.add(Dense(units=32, kernel_initializer='he_uniform', activation='relu')) #Hidden Layers\n",
    "ann_class.add(Dropout(0.3))\n",
    "ann_class.add(Dense(units=8, kernel_initializer='he_uniform', activation='relu'))#Hidden Layers\n",
    "ann_class.add(Dropout(0.2))\n",
    "ann_class.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid')) #Output Layer\n",
    "\n",
    "ann_class.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ann_class.fit(xtrain, ytrain, validation_split=0.1, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction:\n",
    "ypred = ann_class.predict(xtest)\n",
    "ypred_new = ypred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.57142857142858\n"
     ]
    }
   ],
   "source": [
    "# Accuaracy:\n",
    "print(accuracy_score(ytest, ypred_new)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62  2]\n",
      " [ 0 76]]\n",
      "Sensitivity = 100.0\n",
      "Specificity = 96.875\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix:\n",
    "print(confusion_matrix(ytest, ypred_new))\n",
    "print('Sensitivity =' ,(76/(76+0))*100)\n",
    "print('Specificity =' ,(62/(62+2))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
